{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<h3 align=\"center\"> Deep Learning - Project </h3>**\n",
    "# **<h3 align=\"center\"> Phylum Arthropoda - Steven</h3>**\n",
    "**Group 4 members:**<br>\n",
    "Alexandra Pinto - 20211599@novaims.unl.pt - 20211599<br>\n",
    "Steven Carlson - 20240554@novaims.unl.pt - 20240554<br>\n",
    "Sven Goerdes - 20240503@novaims.unl.pt - 20240503<br>\n",
    "Tim Straub - 20240505@novaims.unl.pt - 20240505<br>\n",
    "Zofia Wojcik  - 20240654@novaims.unl.pt - 20240654<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Setup](#setup)\n",
    "* [3. Data Loading](#dataloading)\n",
    "* [4. Image Preprocessing](#imagepreprocessing)\n",
    "* [5. Neural Networks Models](#nnmodels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "In this second notebook, we will preprocess images from the **Arthropoda** phylum and develop a deep learning model to accurately classify them at the family level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "In this section, we will import the necessary libraries that will be used throughout the notebook. These libraries will help with data handling and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Libraries for image processing\n",
    "from glob import glob\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 07:55:58.445188: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 07:55:59.103038: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745218559.236019     814 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745218559.307556     814 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745218559.578964     814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745218559.579038     814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745218559.579040     814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745218559.579042     814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-21 07:55:59.611183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Libraries from Keras / TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "#Import pre-trained models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Loading <a class=\"anchor\" id=\"dataloading\"></a>\n",
    "\n",
    "Let's open the train and test for Arthropoda Phylum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eol_content_id</th>\n",
       "      <th>eol_page_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14186361</td>\n",
       "      <td>46559486</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>trionychidae</td>\n",
       "      <td>chordata_trionychidae/14186361_46559486_eol-fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29468590</td>\n",
       "      <td>4453294</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>cebidae</td>\n",
       "      <td>chordata_cebidae/29468590_4453294_eol-full-siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22248395</td>\n",
       "      <td>45512569</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>ramphastidae</td>\n",
       "      <td>chordata_ramphastidae/22248395_45512569_eol-fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eol_content_id  eol_page_id   kingdom    phylum        family  \\\n",
       "0        14186361     46559486  animalia  chordata  trionychidae   \n",
       "1        29468590      4453294  animalia  chordata       cebidae   \n",
       "2        22248395     45512569  animalia  chordata  ramphastidae   \n",
       "\n",
       "                                           file_path  \n",
       "0  chordata_trionychidae/14186361_46559486_eol-fu...  \n",
       "1  chordata_cebidae/29468590_4453294_eol-full-siz...  \n",
       "2  chordata_ramphastidae/22248395_45512569_eol-fu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "arthropoda_train = pd.read_csv(\"/home/sacar/DeepLearning2425/train_test_splits/chordata_train.csv\")\n",
    "arthropoda_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eol_content_id</th>\n",
       "      <th>eol_page_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30109933</td>\n",
       "      <td>45518587</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>pardalotidae</td>\n",
       "      <td>chordata_pardalotidae/30109933_45518587_eol-fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8828493</td>\n",
       "      <td>328029</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>mustelidae</td>\n",
       "      <td>chordata_mustelidae/8828493_328029_eol-full-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24592455</td>\n",
       "      <td>46559814</td>\n",
       "      <td>animalia</td>\n",
       "      <td>chordata</td>\n",
       "      <td>carcharhinidae</td>\n",
       "      <td>chordata_carcharhinidae/24592455_46559814_eol-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eol_content_id  eol_page_id   kingdom    phylum          family  \\\n",
       "0        30109933     45518587  animalia  chordata    pardalotidae   \n",
       "1         8828493       328029  animalia  chordata      mustelidae   \n",
       "2        24592455     46559814  animalia  chordata  carcharhinidae   \n",
       "\n",
       "                                           file_path  \n",
       "0  chordata_pardalotidae/30109933_45518587_eol-fu...  \n",
       "1  chordata_mustelidae/8828493_328029_eol-full-si...  \n",
       "2  chordata_carcharhinidae/24592455_46559814_eol-...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "arthropoda_test = pd.read_csv(\"/home/sacar/DeepLearning2425/train_test_splits/chordata_test.csv\")\n",
    "arthropoda_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image Preprocessing <a class=\"anchor\" id=\"imagepreprocessing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map model names to their preprocessors and classes\n",
    "model_map = {\n",
    "    'resnet50':      (ResNet50,      resnet_preprocess),\n",
    "    'MobileNetV2':   (MobileNetV2,   mobilenet_preprocess),\n",
    "    'efficientnetb0':(EfficientNetB0, efficientnet_preprocess),\n",
    "    'densenet121':   (DenseNet121,   densenet_preprocess),\n",
    "    'inceptionv3':   (InceptionV3,   inception_preprocess),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745218564.177404     814 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1745218564.181473     814 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2248 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "#Define preprocess and augmentation functions\n",
    "\n",
    "#Function to preprocess the images\n",
    "def process_image(file_path, label, preprocess_fn):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "\n",
    "    if preprocess_fn:\n",
    "        image = preprocess_fn(image)\n",
    "    else:\n",
    "        # default normalization\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function to augment the images\n",
    "def augment_image(image, label):\n",
    "\n",
    "    #Randomly change brightness\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "\n",
    "    #Apply geometric augmentations\n",
    "    image = geometric_augmentation_layers(image, training=True) # Apply geometric augmentations\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Geometric augmentations\n",
    "geometric_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        # Randomly flip horizontally\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "\n",
    "        # Randomly rotate\n",
    "        tf.keras.layers.RandomRotation(factor=0.12),\n",
    "\n",
    "        # Random zoom\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.35, 0.35), # Corresponds to [0.8, 1.2] of original height\n",
    "                                   width_factor=(-0.35, 0.35)), # Corresponds to [0.8, 1.2] of original width\n",
    "\n",
    "        # Random shift\n",
    "        tf.keras.layers.RandomTranslation(height_factor=0.20,\n",
    "                                          width_factor=0.20),\n",
    "\n",
    "        # Contrast\n",
    "        tf.keras.layers.RandomContrast(factor=0.25),\n",
    "\n",
    "    ],\n",
    "    name=\"geometric_augmentations\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some stuff\n",
    "num_classes = arthropoda_train['family'].nunique() #number of classes = number of families\n",
    "batch_size = 64\n",
    "input_shape = (224, 224, 3)\n",
    "image_size = (224, 224)\n",
    "value_range = (0.0, 1.0)\n",
    "num_classes = 166  \n",
    "\n",
    "# Define callbacks\n",
    "my_callbacks = [\n",
    "callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),\n",
    "callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sacar/DeepLearning2425/rare_species/chordata_trionychidae/14186361_46559486_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_cebidae/29468590_4453294_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_ramphastidae/22248395_45512569_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_dasyatidae/29716270_51263523_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_cheloniidae/12281911_46559476_eol-full-size-copy.jpg']\n",
      "[154  30 128  53  39]\n",
      "['/home/sacar/DeepLearning2425/rare_species/chordata_pardalotidae/30109933_45518587_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_mustelidae/8828493_328029_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_carcharhinidae/24592455_46559814_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_balistidae/29627757_46570656_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/chordata_lutjanidae/9432485_46580724_eol-full-size-copy.jpg']\n",
      "[107  99  28  17  90]\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = \"/content/drive/MyDrive/datasets/chordata_images\"\n",
    "\n",
    "# Construct full image paths\n",
    "chordata_train['full_path'] = chordata_train['file_path'].apply(lambda x: os.path.normpath(os.path.join(root_dir, x)))\n",
    "chordata_test['full_path'] = chordata_test['file_path'].apply(lambda x: os.path.normpath(os.path.join(root_dir, x)))\n",
    "\n",
    "# Extract file paths and labels\n",
    "file_paths_train = chordata_train['full_path'].tolist()\n",
    "labels_train = chordata_train['family'].tolist()\n",
    "\n",
    "file_paths_test = chordata_test['full_path'].tolist()\n",
    "labels_test = chordata_test['family'].tolist()\n",
    "\n",
    "# Map string labels to integer indices\n",
    "label_names = sorted(set(labels_train))\n",
    "label_to_index = {name: i for i, name in enumerate(label_names)}\n",
    "\n",
    "# Encode labels\n",
    "labels_train = [label_to_index[label] for label in labels_train]\n",
    "labels_test = [label_to_index[label] for label in labels_test]\n",
    "\n",
    "# Convert to numpy arrays\n",
    "labels_train = np.array(labels_train, dtype=np.int32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)\n",
    "\n",
    "# --- Train/Validation Split ---\n",
    "combined = list(zip(file_paths_train, labels_train))\n",
    "random.seed(42)\n",
    "random.shuffle(combined)\n",
    "\n",
    "file_paths_train, labels_train = zip(*combined)  # Still tuples at this point\n",
    "split_index = int(0.8 * len(file_paths_train))\n",
    "\n",
    "train_paths = list(file_paths_train[:split_index])\n",
    "train_labels = np.array(labels_train[:split_index], dtype=np.int32)\n",
    "val_paths   = list(file_paths_train[split_index:])\n",
    "val_labels  = np.array(labels_train[split_index:], dtype=np.int32)\n",
    "file_paths_test = list(file_paths_test)  # Ensure it's a list\n",
    "labels_test = np.array(labels_test, dtype=np.int32)\n",
    "\n",
    "print(\"Train size:\", len(train_paths))\n",
    "print(\"Validation size:\", len(val_paths))\n",
    "print(\"Test size:\", len(file_paths_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to build the dataset\n",
    "def build_dataset(file_paths, labels, preprocess_fn, augment=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: process_image(x, y, preprocess_fn), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    if augment:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True, seed=42)\n",
    "    dataset = dataset.batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm GPU is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU(s) detected: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# Print GPU devices detected\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU(s) detected: {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"❌ No GPU detected by TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(train, val, num_classes, base_model_class, n_trials=1, seed=42):\n",
    "    import random, itertools, gc\n",
    "    from tensorflow.keras import layers, models, backend as K\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    import pandas as pd\n",
    "    import tensorflow.keras as keras\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Hyperparameter search space\n",
    "    dropout_rates = [0.5, 0.6, 0.7]\n",
    "    dense_units_list = [64, 128]\n",
    "    learning_rates = [1e-5, 5e-5, 1e-4]\n",
    "    patience_values = [5, 7]\n",
    "    freeze_until_layers = [100, 120, 140]\n",
    "    optimizers_list = ['adam']\n",
    "\n",
    "    # Generate all possible combinations\n",
    "    all_combinations = list(itertools.product(\n",
    "        dropout_rates,\n",
    "        dense_units_list,\n",
    "        learning_rates,\n",
    "        patience_values,\n",
    "        freeze_until_layers,\n",
    "        optimizers_list\n",
    "    ))\n",
    "\n",
    "    sampled_combinations = random.sample(all_combinations, k=min(n_trials, len(all_combinations)))\n",
    "    results = []\n",
    "\n",
    "    # ✅ Load weights only once\n",
    "    base_model_template = base_model_class(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_weights = base_model_template.get_weights()\n",
    "    del base_model_template\n",
    "\n",
    "    for i, (dropout, units, lr, patience, freeze_until, opt_name) in enumerate(sampled_combinations):\n",
    "        print(f\"\\n Trial {i+1}/{len(sampled_combinations)}\")\n",
    "        print(f\"Dropout={dropout}, Units={units}, LR={lr}, Patience={patience}, FreezeUntil={freeze_until}\")\n",
    "\n",
    "        base_model = base_model_class(\n",
    "            input_shape=(224, 224, 3),\n",
    "            include_top=False,\n",
    "            weights=None  # important!\n",
    "        )\n",
    "        base_model.set_weights(base_weights)\n",
    "        base_model.trainable = False\n",
    "\n",
    "        def create_optimizer():\n",
    "            return keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(units, activation='relu'),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=create_optimizer(),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        callbacks_list = [\n",
    "            EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=max(1, patience // 2)),\n",
    "            ModelCheckpoint(f\"{base_model_class.__name__}_V2{i+1}.keras\", save_best_only=True)\n",
    "\n",
    "        ]\n",
    "\n",
    "        # Phase 1 training\n",
    "        history1 = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=30,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Phase 2 fine-tuning\n",
    "        base_model.trainable = True\n",
    "        for layer in base_model.layers[:freeze_until]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=create_optimizer(),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history2 = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=30,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        final_val_acc = history2.history['val_accuracy'][-1]\n",
    "\n",
    "        results.append({\n",
    "            'dropout': dropout,\n",
    "            'dense_units': units,\n",
    "            'learning_rate': lr,\n",
    "            'patience': patience,\n",
    "            'freeze_until': freeze_until,\n",
    "            'optimizer': opt_name,\n",
    "            'val_accuracy': final_val_acc\n",
    "        })\n",
    "\n",
    "        \n",
    "\n",
    "    # ✅ RETURN after the loop ends\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_random_search_results(results_df, top_n=5):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Top N Configurations by Val Accuracy\n",
    "    # -------------------------------\n",
    "    top_configs = results_df.sort_values(by='val_accuracy', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=top_configs, x='val_accuracy', y=top_configs.index, hue='dropout')\n",
    "    plt.title(f\"Top {top_n} Hyperparameter Configs by Validation Accuracy\")\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"Config Index\")\n",
    "    plt.legend(title=\"Dropout\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Strip plots: Accuracy vs Each Hyperparam\n",
    "    # -------------------------------\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle(\"Validation Accuracy vs Hyperparameters\", fontsize=16)\n",
    "\n",
    "    sns.stripplot(data=results_df, x='dropout', y='val_accuracy', ax=axs[0, 0])\n",
    "    axs[0, 0].set_title(\"Dropout\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='dense_units', y='val_accuracy', ax=axs[0, 1])\n",
    "    axs[0, 1].set_title(\"Dense Units\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='learning_rate', y='val_accuracy', ax=axs[0, 2])\n",
    "    axs[0, 2].set_title(\"Learning Rate\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='patience', y='val_accuracy', ax=axs[1, 0])\n",
    "    axs[1, 0].set_title(\"EarlyStopping Patience\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='freeze_until', y='val_accuracy', ax=axs[1, 1])\n",
    "    axs[1, 1].set_title(\"Freeze Until Layer\")\n",
    "\n",
    "    axs[1, 2].axis('off')  # Empty slot\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Heatmap (e.g. Dropout vs Units)\n",
    "    # -------------------------------\n",
    "    pivot_table = results_df.pivot_table(\n",
    "        values='val_accuracy',\n",
    "        index='dropout',\n",
    "        columns='dense_units',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "    plt.title(\"Heatmap: Dropout vs Dense Units (Val Accuracy)\")\n",
    "    plt.xlabel(\"Dense Units\")\n",
    "    plt.ylabel(\"Dropout Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running model: MobileNetV2\n",
      "\n",
      "\n",
      " Trial 1/15\n",
      "Dropout=0.7, Units=64, LR=5e-05, Patience=7, FreezeUntil=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745218584.741927    2621 service.cc:152] XLA service 0x7fe574004140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745218584.743296    2621 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-04-21 07:56:24.942459: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745218586.650406    2621 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1745218592.240230    2621 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "# Example model list — customize as needed\n",
    "models_list = ['inceptionv3']\n",
    "\n",
    "for model_name in models_list:\n",
    "    print(f\"\\n>>> Running model: {model_name}\\n\")\n",
    "\n",
    "    # Get model constructor and preprocessing function from your model map\n",
    "    base_model_class, preprocess_fn = model_map[model_name]\n",
    "\n",
    "    # ✅ Build datasets using clean inputs\n",
    "    train = build_dataset(train_paths, train_labels, preprocess_fn, augment=True)\n",
    "    val   = build_dataset(val_paths, val_labels, preprocess_fn, augment=False)\n",
    "    test  = build_dataset(file_paths_test, labels_test, preprocess_fn, augment=False)\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    results = run_random_search(\n",
    "        train, val, num_classes,\n",
    "        base_model_class=base_model_class,\n",
    "        n_trials=15,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Plot results\n",
    "    plot_random_search_results(results, top_n=1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_wsl_env)",
   "language": "python",
   "name": "tf_wsl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
