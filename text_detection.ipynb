{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for text detection in images.\n",
    "Returns 1 for text and 0 for no text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import easyocr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up EasyOCR reader\n",
    "reader = easyocr.Reader(['en'],gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name)\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Check if the file contains text or not\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         has_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m         images_with_text\u001b[38;5;241m.\u001b[39mappend(file_path) \u001b[38;5;28;01mif\u001b[39;00m has_text \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(images_with_text)\n",
      "File \u001b[1;32mc:\\Users\\sacar\\OneDrive\\Documents\\Semester 2 NOVA\\DL\\DeepLearning2425\\tf_env39\\lib\\site-packages\\easyocr\\easyocr.py:468\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    467\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 468\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizontal_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\sacar\\OneDrive\\Documents\\Semester 2 NOVA\\DL\\DeepLearning2425\\tf_env39\\lib\\site-packages\\easyocr\\easyocr.py:383\u001b[0m, in \u001b[0;36mReader.recognize\u001b[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001b[0m\n\u001b[0;32m    381\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [bbox]\n\u001b[0;32m    382\u001b[0m f_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 383\u001b[0m image_list, max_width \u001b[38;5;241m=\u001b[39m \u001b[43mget_image_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimgH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m result0 \u001b[38;5;241m=\u001b[39m get_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharacter, imgH, \u001b[38;5;28mint\u001b[39m(max_width), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter, image_list,\\\n\u001b[0;32m    385\u001b[0m               ignore_char, decoder, beamWidth, batch_size, contrast_ths, adjust_contrast, filter_ths,\\\n\u001b[0;32m    386\u001b[0m               workers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    387\u001b[0m result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result0\n",
      "File \u001b[1;32mc:\\Users\\sacar\\OneDrive\\Documents\\Semester 2 NOVA\\DL\\DeepLearning2425\\tf_env39\\lib\\site-packages\\easyocr\\utils.py:613\u001b[0m, in \u001b[0;36mget_image_list\u001b[1;34m(horizontal_list, free_list, img, model_height, sort_output)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 613\u001b[0m     crop_img,ratio \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ratio_and_resize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m     image_list\u001b[38;5;241m.\u001b[39mappend( ( [[x_min,y_min],[x_max,y_min],[x_max,y_max],[x_min,y_max]] ,crop_img) )\n\u001b[0;32m    615\u001b[0m     max_ratio_hori \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(ratio, max_ratio_hori)\n",
      "File \u001b[1;32mc:\\Users\\sacar\\OneDrive\\Documents\\Semester 2 NOVA\\DL\\DeepLearning2425\\tf_env39\\lib\\site-packages\\easyocr\\utils.py:574\u001b[0m, in \u001b[0;36mcompute_ratio_and_resize\u001b[1;34m(img, width, height, model_height)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m    573\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m calculate_ratio(width,height)\n\u001b[1;32m--> 574\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(\u001b[38;5;28mint\u001b[39m(model_height\u001b[38;5;241m*\u001b[39mratio),model_height),interpolation\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mResampling\u001b[38;5;241m.\u001b[39mLANCZOS)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store images without text\n",
    "images_with_text = []\n",
    "\n",
    "# Iterate through the folders and files in the specified directory\n",
    "root_dir = r\"C:\\Users\\sacar\\OneDrive\\Documents\\Semester 2 NOVA\\DL\\DeepLearning2425\\rare_species\"\n",
    "for folder_name in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder_name)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file contains text or not\n",
    "        has_text = bool(reader.readtext(file_path))\n",
    "        images_with_text.append(file_path) if has_text else None\n",
    "\n",
    "print(images_with_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
