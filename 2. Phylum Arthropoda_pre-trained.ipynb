{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<h3 align=\"center\"> Deep Learning - Project </h3>**\n",
    "# **<h3 align=\"center\"> Phylum Arthropoda - Steven</h3>**\n",
    "**Group 4 members:**<br>\n",
    "Alexandra Pinto - 20211599@novaims.unl.pt - 20211599<br>\n",
    "Steven Carlson - 20240554@novaims.unl.pt - 20240554<br>\n",
    "Sven Goerdes - 20240503@novaims.unl.pt - 20240503<br>\n",
    "Tim Straub - 20240505@novaims.unl.pt - 20240505<br>\n",
    "Zofia Wojcik  - 20240654@novaims.unl.pt - 20240654<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Setup](#setup)\n",
    "* [3. Data Loading](#dataloading)\n",
    "* [4. Image Preprocessing](#imagepreprocessing)\n",
    "* [5. Neural Networks Models](#nnmodels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "In this second notebook, we will preprocess images from the **Arthropoda** phylum and develop a deep learning model to accurately classify them at the family level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "In this section, we will import the necessary libraries that will be used throughout the notebook. These libraries will help with data handling and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Libraries for image processing\n",
    "from glob import glob\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries from Keras / TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "#Import pre-trained models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Loading <a class=\"anchor\" id=\"dataloading\"></a>\n",
    "\n",
    "Let's open the train and test for Arthropoda Phylum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eol_content_id</th>\n",
       "      <th>eol_page_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28260809</td>\n",
       "      <td>1065329</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>apidae</td>\n",
       "      <td>arthropoda_apidae/28260809_1065329_eol-full-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29945328</td>\n",
       "      <td>1077217</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>pseudophasmatidae</td>\n",
       "      <td>arthropoda_pseudophasmatidae/29945328_1077217_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14644212</td>\n",
       "      <td>463474</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>formicidae</td>\n",
       "      <td>arthropoda_formicidae/14644212_463474_eol-full...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eol_content_id  eol_page_id   kingdom      phylum             family  \\\n",
       "0        28260809      1065329  animalia  arthropoda             apidae   \n",
       "1        29945328      1077217  animalia  arthropoda  pseudophasmatidae   \n",
       "2        14644212       463474  animalia  arthropoda         formicidae   \n",
       "\n",
       "                                           file_path  \n",
       "0  arthropoda_apidae/28260809_1065329_eol-full-si...  \n",
       "1  arthropoda_pseudophasmatidae/29945328_1077217_...  \n",
       "2  arthropoda_formicidae/14644212_463474_eol-full...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "arthropoda_train = pd.read_csv(\"/home/sacar/DeepLearning2425/train_test_splits/arthropoda_train.csv\")\n",
    "arthropoda_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eol_content_id</th>\n",
       "      <th>eol_page_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>family</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28408206</td>\n",
       "      <td>1065346</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>apidae</td>\n",
       "      <td>arthropoda_apidae/28408206_1065346_eol-full-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28253620</td>\n",
       "      <td>1065348</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>apidae</td>\n",
       "      <td>arthropoda_apidae/28253620_1065348_eol-full-si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21847584</td>\n",
       "      <td>1065348</td>\n",
       "      <td>animalia</td>\n",
       "      <td>arthropoda</td>\n",
       "      <td>apidae</td>\n",
       "      <td>arthropoda_apidae/21847584_1065348_eol-full-si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eol_content_id  eol_page_id   kingdom      phylum  family  \\\n",
       "0        28408206      1065346  animalia  arthropoda  apidae   \n",
       "1        28253620      1065348  animalia  arthropoda  apidae   \n",
       "2        21847584      1065348  animalia  arthropoda  apidae   \n",
       "\n",
       "                                           file_path  \n",
       "0  arthropoda_apidae/28408206_1065346_eol-full-si...  \n",
       "1  arthropoda_apidae/28253620_1065348_eol-full-si...  \n",
       "2  arthropoda_apidae/21847584_1065348_eol-full-si...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "arthropoda_test = pd.read_csv(\"/home/sacar/DeepLearning2425/train_test_splits/arthropoda_test.csv\")\n",
    "arthropoda_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image Preprocessing <a class=\"anchor\" id=\"imagepreprocessing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control Panel -- Choose one model to run!\n",
    "is_resnet = 0\n",
    "is_mobilenet = 1\n",
    "is_efficientnet = 0\n",
    "is_densenet = 0\n",
    "is_inception = 0\n",
    "is_convnext = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define preprocess and augmentation functions\n",
    "\n",
    "#Function to preprocess the images\n",
    "def process_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path) # Read the image file\n",
    "    image = tf.image.decode_jpeg(image, channels=3) # Decode the JPEG image\n",
    "    image = tf.image.resize(image, image_size) # Resize the image to the target size\n",
    "    \n",
    "    #CHANGE THIS LINE DEPENDING ON WHICH PRE-TRAINED MODEL IS BEING USED\n",
    "    \n",
    "    if is_resnet:\n",
    "        image = resnet_preprocess(image)  # Apply ResNet50 preprocessing\n",
    "        print(\"ResNet50 preprocessing applied\")\n",
    "    elif is_mobilenet: \n",
    "        image = mobilenet_preprocess(image)  # Apply MobileNetV2 preprocessing\n",
    "        print\n",
    "    elif is_efficientnet:\n",
    "        image = efficientnet_preprocess(image)  # Apply EfficientNetB0 preprocessing\n",
    "        print(\"EfficientNetB0 preprocessing applied\")\n",
    "    elif is_densenet:\n",
    "        image = densenet_preprocess(image)  # Apply DenseNet121 preprocessing\n",
    "        print(\"DenseNet121 preprocessing applied\")\n",
    "    elif is_inception:\n",
    "        image = inception_preprocess(image)  # Apply InceptionV3 preprocessing\n",
    "        print(\"InceptionV3 preprocessing applied\")\n",
    "    else:\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Apply ConvNeXt / default preprocessing\n",
    "        print(\"ConvNeXt preprocessing applied\")\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "#Function to augment the images\n",
    "def augment_image(image, label):\n",
    "\n",
    "    #Randomly change brightness\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "\n",
    "    #Apply geometric augmentations\n",
    "    image = geometric_augmentation_layers(image, training=True) # Apply geometric augmentations\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Geometric augmentations\n",
    "geometric_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        # Randomly flip horizontally\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "\n",
    "        # Randomly rotate\n",
    "        tf.keras.layers.RandomRotation(factor=0.12),\n",
    "\n",
    "        # Random zoom\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.35, 0.35), # Corresponds to [0.8, 1.2] of original height\n",
    "                                   width_factor=(-0.35, 0.35)), # Corresponds to [0.8, 1.2] of original width\n",
    "\n",
    "        # Random shift\n",
    "        tf.keras.layers.RandomTranslation(height_factor=0.20,\n",
    "                                          width_factor=0.20),\n",
    "\n",
    "        # Contrast\n",
    "        tf.keras.layers.RandomContrast(factor=0.25),\n",
    "\n",
    "    ],\n",
    "    name=\"geometric_augmentations\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define some stuff\n",
    "num_classes = arthropoda_train['family'].nunique() #number of classes = number of families\n",
    "batch_size = 64\n",
    "input_shape = (224, 224, 3)\n",
    "image_size = (224, 224)\n",
    "value_range = (0.0, 1.0)\n",
    "num_classes = 17  \n",
    "\n",
    "# Define callbacks\n",
    "my_callbacks = [\n",
    "callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),\n",
    "callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sacar/DeepLearning2425/rare_species/arthropoda_apidae/28260809_1065329_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_pseudophasmatidae/29945328_1077217_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_formicidae/14644212_463474_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_pseudophasmatidae/29945335_1077217_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_papilionidae/21035374_130548_eol-full-size-copy.jpg']\n",
      "[0, 13, 5, 13, 10]\n",
      "['/home/sacar/DeepLearning2425/rare_species/arthropoda_apidae/28408206_1065346_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_apidae/28253620_1065348_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_apidae/21847584_1065348_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_formicidae/14681521_403723_eol-full-size-copy.jpg', '/home/sacar/DeepLearning2425/rare_species/arthropoda_palinuridae/30050875_46516728_eol-full-size-copy.jpg']\n",
      "[0, 0, 0, 5, 9]\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/sacar/DeepLearning2425/rare_species\"\n",
    "\n",
    "#Get the file paths and labels for the training and test set\n",
    "arthropoda_train['full_path'] = arthropoda_train['file_path'].apply(lambda x: os.path.normpath(os.path.join(root_dir, x)))\n",
    "arthropoda_test['full_path'] = arthropoda_test['file_path'].apply(lambda x: os.path.normpath(os.path.join(root_dir, x)))\n",
    "\n",
    "file_paths_train = arthropoda_train['full_path'].tolist()\n",
    "labels_train = arthropoda_train['family'].tolist()\n",
    "\n",
    "file_paths_test = arthropoda_test['full_path'].tolist()\n",
    "labels_test = arthropoda_test['family'].tolist()\n",
    "\n",
    "#Map the labels to integers\n",
    "label_names = sorted(set(labels_train)) # Get the unique labels\n",
    "label_to_index = {name: i for i, name in enumerate(label_names)} # Create a mapping from labels to integers\n",
    "labels_train = [label_to_index[label] for label in labels_train]\n",
    "labels_test = [label_to_index[label] for label in labels_test]\n",
    "\n",
    "print(file_paths_train[:5])\n",
    "print(labels_train[:5])\n",
    "print(file_paths_test[:5])\n",
    "print(labels_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tensorflow datasets\n",
    "\n",
    "#Load data\n",
    "data = tf.data.Dataset.from_tensor_slices((file_paths_train, labels_train))\n",
    "data = data.shuffle(buffer_size=len(file_paths_train), reshuffle_each_iteration=False, seed=42) # Shuffle the dataset\n",
    "\n",
    "#Create train/val\n",
    "train_size = int(0.8 * len(file_paths_train)) #80% for training, 20% for validation\n",
    "train = data.take(train_size) # Take the first 80% for training\n",
    "val = data.skip(train_size) # Skip the first 80% for validation\n",
    "\n",
    "#Training preprocess pipeline\n",
    "train = train.map(process_image, num_parallel_calls=tf.data.AUTOTUNE) # Map the function to the dataset\n",
    "train = train.cache() # Cache the dataset for faster access\n",
    "train = train.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE) # Map the function to the dataset\n",
    "train = train.shuffle(buffer_size=1000, reshuffle_each_iteration=True, seed=42).batch(32).prefetch(buffer_size=tf.data.AUTOTUNE) #shuffle and batch\n",
    "\n",
    "#Validation preprocess pipeline\n",
    "val = val.map(process_image, num_parallel_calls=tf.data.AUTOTUNE) # Map the function to the dataset\n",
    "val = val.cache() # Cache the dataset for faster access\n",
    "val = val.batch(32).prefetch(buffer_size=tf.data.AUTOTUNE) #batch\n",
    "\n",
    "\n",
    "#Test preprocess pipeline\n",
    "test = tf.data.Dataset.from_tensor_slices((file_paths_test, labels_test))\n",
    "test = test.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test = test.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [ 0  8  5  5  2  8  0  5  4  0  5  5  5  6  0  1  3  5  3 11  6 10  1  3\n",
      "  0  0  0  0 14  5 10  5]\n",
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [11  5  5 12  7  5 15  2  5  0  6 13  5  6  1  5 16 12 14  5  5  4 13  0\n",
      "  5 15  7  6  7  0 14  5]\n",
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [16  0 11 13 13  1  5  3  6  3  5  8  1  5 11 10  6  6  5  2  9  5  0  5\n",
      "  5  2  5  4 10  5  0  0]\n",
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [ 0  0  0  5  9  0 16  5  5  5  0 16  6  0 11  0  0  5 13  5  5  8  5  0\n",
      " 16  7  7  2  5  6  8  0]\n",
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [ 5 12 15  0  5 14 12 11  8  0  5  6 12  0  6  0  3  5  5  1  5  5  7  0\n",
      "  0  3 13  0  7  5  5  5]\n",
      "Image shape: (32, 224, 224, 3)\n",
      "Label: [13  2  5  9 14  5  6  0  5  5  7  5 15  0 15 10  4  0 14  1  5  5  5  5\n",
      "  0  2  5 10  3  0 11  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 20:14:59.730339: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-04-10 20:14:59.740877: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for image, label in train.take(3):\n",
    "    print(\"Image shape:\", image.numpy().shape)\n",
    "    print(\"Label:\", label.numpy())\n",
    "\n",
    "for image, label in test.take(3):\n",
    "    print(\"Image shape:\", image.numpy().shape)\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural Network Models <a class=\"anchor\" id=\"nnmodels\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU(s) detected: ['/physical_device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "# Print GPU devices detected\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU(s) detected: {[gpu.name for gpu in gpus]}\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected by TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_resnet == 1:\n",
    "    # 1. Load the ResNet50 base model (without top classifier)\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',          # Use ImageNet pretrained weights\n",
    "        include_top=False,           # Exclude the default final dense layer\n",
    "        input_shape=(224, 224, 3)    # Adjust to match your input images\n",
    "    )\n",
    "\n",
    "    # 2. Freeze the base model so we only train the classifier head\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # 3. Build custom classification head\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "    # 4. Create the full model\n",
    "    model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # 5. Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='sparse_categorical_crossentropy',  # ‚úÖ Use sparse version for integer labels\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    # 6. Train the model\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        epochs=100,\n",
    "        validation_data=val,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 7. Save the model\n",
    "    model.save(\"resnet50_rare_species_model.h5\")\n",
    "\n",
    "    plot_filename = 'resnet50_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['f1_score'])\n",
    "    plt.plot(history.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif is_mobilenet == 1:\\n    # Load base model without top layer\\n    base_model = MobileNetV2(\\n        input_shape=(224, 224, 3),  # Match your resized image shape\\n        include_top=False,         # Don\\'t include the original classifier\\n        weights=\\'imagenet\\'         # Use ImageNet-pretrained weights\\n    )\\n\\n    # Define callbacks\\n    my_callbacks = [\\n    callbacks.EarlyStopping(patience=10, restore_best_weights=True),\\n    callbacks.ReduceLROnPlateau(monitor=\\'val_loss\\', factor=0.5, patience=5),\\n    callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\\n    ]\\n\\n\\n    #Phase 1: \\n    # Freeze base model so we only train the new layers for now\\n    base_model.trainable = False\\n\\n    # Build custom model\\n    model = models.Sequential([\\n        base_model,                                # Feature extractor\\n        layers.GlobalAveragePooling2D(),           # Pool over spatial dimensions\\n        layers.Dropout(0.5),                       # Regularization layer\\n        layers.Dense(256, activation=\\'relu\\'),      # Fully connected layer\\n        layers.Dense(num_classes, activation=\\'softmax\\')      # Output layer (5 mollusk families)\\n    ])\\n\\n    # Compile model\\n    model.compile(\\n        optimizer=optimizers.Adam(learning_rate=1e-4),\\n        loss=\\'sparse_categorical_crossentropy\\',  # Use sparse version for integer labels\\n        metrics=[\\'accuracy\\'],\\n    )\\n\\n    # Train the model\\n    history1 = model.fit(\\n        train,\\n        validation_data=val,\\n        callbacks = my_callbacks,\\n        epochs=100,           # Start small, increase if needed\\n        verbose=1\\n    )\\n\\n    #Phase 2:\\n    # Unfreeze everything but the first 100 layers\\n    base_model.trainable = True\\n    for layer in base_model.layers[:100]:\\n        layer.trainable = False\\n\\n    # Compile model\\n    model.compile(\\n        optimizer=optimizers.Adam(learning_rate=1e-4),\\n        loss=\\'sparse_categorical_crossentropy\\',  # Use sparse version for integer labels\\n        metrics=[\\'accuracy\\'],\\n    )\\n\\n    # Train the model\\n    history2 = model.fit(\\n        train,\\n        validation_data=val,\\n        callbacks = my_callbacks,\\n        epochs=100,           # Start small, increase if needed\\n        verbose=1\\n    )\\n\\n    # Save the model\\n    model.save(\"mobilenetv2_rare_species_model.h5\")\\n\\n    # Plot training & validation accuracy\\n    plt.figure(figsize=(12, 5))\\n    plt.plot(history2.history[\\'accuracy\\'])\\n    plt.plot(history2.history[\\'val_accuracy\\'])\\n    plt.title(\\'Model accuracy\\')\\n    plt.ylabel(\\'Accuracy\\')\\n    plt.xlabel(\\'Epoch\\')\\n    plt.legend([\\'Train\\', \\'Val\\'])\\n    plt.show()\\n\\n    #Plot training & validation F1 score\\n    plt.figure(figsize=(12, 5))\\n    plt.plot(history2.history[\\'f1_score\\'])\\n    plt.plot(history2.history[\\'val_f1_score\\'])\\n    plt.title(\\'Model F1 Score\\')\\n    plt.ylabel(\\'F1 Score\\')\\n    plt.xlabel(\\'Epoch\\')\\n    plt.legend([\\'Train\\', \\'Val\\'])\\n    plt.show()\\n\\n    #Plot training & validation loss\\n    plt.figure(figsize=(12, 5))\\n    plt.plot(history2.history[\\'loss\\'])\\n    plt.plot(history2.history[\\'val_loss\\'])\\n    plt.title(\\'Model Loss\\')\\n    plt.ylabel(\\'Loss\\')\\n    plt.xlabel(\\'Epoch\\')\\n    plt.legend([\\'Train\\', \\'Val\\'])\\n    plt.show()\\n\\n\\n    plot_filename = \\'mobilenetV2_rare_species_1.png\\' # Match naming convention\\n    plt.savefig(plot_filename)\\n    print(f\"Training plot saved to {plot_filename}\")\\n    '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if is_mobilenet == 1:\n",
    "    # Load base model without top layer\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(224, 224, 3),  # Match your resized image shape\n",
    "        include_top=False,         # Don't include the original classifier\n",
    "        weights='imagenet'         # Use ImageNet-pretrained weights\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    my_callbacks = [\n",
    "    callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),\n",
    "    callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "    ]\n",
    "\n",
    "\n",
    "    #Phase 1: \n",
    "    # Freeze base model so we only train the new layers for now\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build custom model\n",
    "    model = models.Sequential([\n",
    "        base_model,                                # Feature extractor\n",
    "        layers.GlobalAveragePooling2D(),           # Pool over spatial dimensions\n",
    "        layers.Dropout(0.5),                       # Regularization layer\n",
    "        layers.Dense(256, activation='relu'),      # Fully connected layer\n",
    "        layers.Dense(num_classes, activation='softmax')      # Output layer (5 mollusk families)\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',  # Use sparse version for integer labels\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history1 = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        callbacks = my_callbacks,\n",
    "        epochs=100,           # Start small, increase if needed\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    #Phase 2:\n",
    "    # Unfreeze everything but the first 100 layers\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',  # Use sparse version for integer labels\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history2 = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        callbacks = my_callbacks,\n",
    "        epochs=100,           # Start small, increase if needed\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"mobilenetv2_rare_species_model.h5\")\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history2.history['accuracy'])\n",
    "    plt.plot(history2.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history2.history['f1_score'])\n",
    "    plt.plot(history2.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "    \n",
    "    #Plot training & validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history2.history['loss'])\n",
    "    plt.plot(history2.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plot_filename = 'mobilenetV2_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(train, val, num_classes, n_trials=15, seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Hyperparameter search space\n",
    "    dropout_rates = [0.5, 0.6, 0.7]\n",
    "    dense_units_list = [64, 128]\n",
    "    learning_rates = [1e-5, 5e-5, 1e-4]\n",
    "    patience_values = [5, 7]\n",
    "    freeze_until_layers = [100, 120, 140]\n",
    "    optimizers_list = ['adam']\n",
    "\n",
    "    # Generate all possible combinations\n",
    "    all_combinations = list(itertools.product(\n",
    "        dropout_rates,\n",
    "        dense_units_list,\n",
    "        learning_rates,\n",
    "        patience_values,\n",
    "        freeze_until_layers,\n",
    "        optimizers_list\n",
    "    ))\n",
    "\n",
    "    # Randomly sample N trials\n",
    "    sampled_combinations = random.sample(all_combinations, k=min(n_trials, len(all_combinations)))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, (dropout, units, lr, patience, freeze_until, opt_name) in enumerate(sampled_combinations):\n",
    "        print(f\"\\n Trial {i+1}/{len(sampled_combinations)}\")\n",
    "        print(f\"Dropout={dropout}, Units={units}, LR={lr}, Patience={patience}, FreezeUntil={freeze_until}\")\n",
    "\n",
    "        # Optimizer selection\n",
    "        optimizer = optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "        # --- Phase 1 ---\n",
    "        base_model = MobileNetV2(\n",
    "            input_shape=(224, 224, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(dropout),\n",
    "            layers.Dense(units, activation='relu'),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        callbacks_list = [\n",
    "            EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=max(1, patience // 2)),\n",
    "            ModelCheckpoint(\"temp_best_model.h5\", save_best_only=True)\n",
    "        ]\n",
    "\n",
    "        history1 = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=30,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # --- Phase 2 ---\n",
    "        base_model.trainable = True\n",
    "        for layer in base_model.layers[:freeze_until]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history2 = model.fit(\n",
    "            train,\n",
    "            validation_data=val,\n",
    "            epochs=30,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        final_val_acc = history2.history['val_accuracy'][-1]\n",
    "        results.append({\n",
    "            'dropout': dropout,\n",
    "            'dense_units': units,\n",
    "            'learning_rate': lr,\n",
    "            'patience': patience,\n",
    "            'freeze_until': freeze_until,\n",
    "            'optimizer': opt_name,\n",
    "            'val_accuracy': final_val_acc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_search_results(results_df, top_n=10):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1. Top N Configurations by Val Accuracy\n",
    "    # -------------------------------\n",
    "    top_configs = results_df.sort_values(by='val_accuracy', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=top_configs, x='val_accuracy', y=top_configs.index, hue='dropout')\n",
    "    plt.title(f\"Top {top_n} Hyperparameter Configs by Validation Accuracy\")\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"Config Index\")\n",
    "    plt.legend(title=\"Dropout\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2. Strip plots: Accuracy vs Each Hyperparam\n",
    "    # -------------------------------\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle(\"Validation Accuracy vs Hyperparameters\", fontsize=16)\n",
    "\n",
    "    sns.stripplot(data=results_df, x='dropout', y='val_accuracy', ax=axs[0, 0])\n",
    "    axs[0, 0].set_title(\"Dropout\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='dense_units', y='val_accuracy', ax=axs[0, 1])\n",
    "    axs[0, 1].set_title(\"Dense Units\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='learning_rate', y='val_accuracy', ax=axs[0, 2])\n",
    "    axs[0, 2].set_title(\"Learning Rate\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='patience', y='val_accuracy', ax=axs[1, 0])\n",
    "    axs[1, 0].set_title(\"EarlyStopping Patience\")\n",
    "\n",
    "    sns.stripplot(data=results_df, x='freeze_until', y='val_accuracy', ax=axs[1, 1])\n",
    "    axs[1, 1].set_title(\"Freeze Until Layer\")\n",
    "\n",
    "    axs[1, 2].axis('off')  # Empty slot\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Heatmap (e.g. Dropout vs Units)\n",
    "    # -------------------------------\n",
    "    pivot_table = results_df.pivot_table(\n",
    "        values='val_accuracy',\n",
    "        index='dropout',\n",
    "        columns='dense_units',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"viridis\")\n",
    "    plt.title(\"Heatmap: Dropout vs Dense Units (Val Accuracy)\")\n",
    "    plt.xlabel(\"Dense Units\")\n",
    "    plt.ylabel(\"Dropout Rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Trial 1/15\n",
      "Dropout=0.7, Units=64, LR=5e-05, Patience=7, FreezeUntil=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744312507.976793   98264 service.cc:152] XLA service 0x7fa7e80112d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1744312507.977064   98264 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-04-10 20:15:08.096112: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1744312509.158690   98264 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1744312516.788084   98264 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "numpy() is only available when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mobilenet == \u001b[32m1\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     random_results = \u001b[43mrun_random_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     random_results = random_results.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m     random_results.to_csv(\u001b[33m\"\u001b[39m\u001b[33mrandom_results.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mrun_random_search\u001b[39m\u001b[34m(train, val, num_classes, n_trials, seed)\u001b[39m\n\u001b[32m     74\u001b[39m     layer.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     76\u001b[39m model.compile(\n\u001b[32m     77\u001b[39m     optimizer=optimizer,\n\u001b[32m     78\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     79\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     80\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m history2 = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     88\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m final_val_acc = history2.history[\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     91\u001b[39m results.append({\n\u001b[32m     92\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m: dropout,\n\u001b[32m     93\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdense_units\u001b[39m\u001b[33m'\u001b[39m: units,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m: final_val_acc\n\u001b[32m     99\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf_wsl_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tf_wsl_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:158\u001b[39m, in \u001b[36mconvert_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf.RaggedTensor):\n\u001b[32m    157\u001b[39m     x = x.to_tensor()\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: numpy() is only available when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "if is_mobilenet == 1:\n",
    "    random_results = run_random_search(train, val, num_classes)\n",
    "    random_results = random_results.sort_values(by='val_accuracy', ascending=False)\n",
    "    random_results.to_csv(\"random_results.csv\", index=False)\n",
    "    print(random_results.head(10))\n",
    "    plot_grid_search_results(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_efficientnet == 1:\n",
    "    # Load EfficientNetB0 as base model\n",
    "    base_model = EfficientNetB0(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build classifier on top\n",
    "    model = models.Sequential([\n",
    "        base_model,                                # Feature extractor\n",
    "        layers.GlobalAveragePooling2D(),           # Pool features\n",
    "        layers.Dropout(0.3),                       # Regularization\n",
    "        layers.Dense(128, activation='relu'),      # Fully connected layer\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    model.summary()\n",
    "\n",
    "    # Train it\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=100,         # Adjust as needed\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    #Save the model\n",
    "    model.save(\"efficientnet_rare_species_model.h5\")\n",
    "    \n",
    "    plot_filename = 'efficientnet_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['f1_score'])\n",
    "    plt.plot(history.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_densenet == 1:\n",
    "    base_model = DenseNet121(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=100,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"densenet_rare_species_model.h5\")\n",
    "\n",
    "    plot_filename = 'densenet_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['f1_score'])\n",
    "    plt.plot(history.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_inception == 1:\n",
    "    base_model = InceptionV3(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=100,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    #Save the model\n",
    "    model.save(\"inception_rare_species_model.h5\")\n",
    "\n",
    "    plot_filename = 'inceptionV3_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['f1_score'])\n",
    "    plt.plot(history.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_convnext == 1:\n",
    "    base_model = tf.keras.Sequential([\n",
    "        hub.KerasLayer(\n",
    "            \"https://tfhub.dev/sayakpaul/convnext_tiny_1k_224/1\",\n",
    "            trainable=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=100,\n",
    "        verbose=1)\n",
    "    \n",
    "    #Save the model\n",
    "    model.save(\"convnext_rare_species_model.h5\")\n",
    "\n",
    "    plot_filename = 'convnext_rare_species_1.png' # Match naming convention\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Training plot saved to {plot_filename}\")\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot training & validation F1 score\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(history.history['f1_score'])\n",
    "    plt.plot(history.history['val_f1_score'])\n",
    "    plt.title('Model F1 Score')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_wsl_env)",
   "language": "python",
   "name": "tf_wsl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
